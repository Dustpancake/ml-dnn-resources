{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC and AUC in Multiclass-Classifiers\n",
    "When there is more than one outcome that we would like to predict, we require more than one output neuron, with each neuron qualifying the confidence of that outcome. Let us build a model on a sample data set using a multiclass NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>crime</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>kd</td>\n",
       "      <td>c</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.207723</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.361216</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>51017.0</td>\n",
       "      <td>38.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>34</td>\n",
       "      <td>14.013489</td>\n",
       "      <td>41</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.104838</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>26576.0</td>\n",
       "      <td>33.358333</td>\n",
       "      <td>2</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>20</td>\n",
       "      <td>8.380497</td>\n",
       "      <td>38</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.063851</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28595.0</td>\n",
       "      <td>39.425000</td>\n",
       "      <td>3</td>\n",
       "      <td>7.168218</td>\n",
       "      <td>99</td>\n",
       "      <td>4.626950</td>\n",
       "      <td>36</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.098703</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>qp</td>\n",
       "      <td>c</td>\n",
       "      <td>67949.0</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>8.936292</td>\n",
       "      <td>26</td>\n",
       "      <td>3.281439</td>\n",
       "      <td>46</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.117803</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>61467.0</td>\n",
       "      <td>16.891667</td>\n",
       "      <td>0</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>8</td>\n",
       "      <td>9.405648</td>\n",
       "      <td>48</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>0.451973</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id job area   income     aspect  subscriptions  dist_healthy  \\\n",
       "0        1  vv    c  50876.0  13.100000              1      9.017895   \n",
       "1        2  kd    c  60369.0  18.625000              2      7.766643   \n",
       "2        3  pe    c  55126.0  34.766667              1      3.632069   \n",
       "3        4  11    c  51690.0  15.808333              1      5.372942   \n",
       "4        5  kl    d  28347.0  40.941667              3      3.822477   \n",
       "...    ...  ..  ...      ...        ...            ...           ...   \n",
       "1995  1996  vv    c  51017.0  38.233333              1      5.454545   \n",
       "1996  1997  kl    d  26576.0  33.358333              2      3.632069   \n",
       "1997  1998  kl    d  28595.0  39.425000              3      7.168218   \n",
       "1998  1999  qp    c  67949.0   5.733333              0      8.936292   \n",
       "1999  2000  pe    c  61467.0  16.891667              0      4.312097   \n",
       "\n",
       "      save_rate  dist_unhealthy  age  pop_dense  retail_dense     crime  \\\n",
       "0            35       11.738935   49   0.885827      0.492126  0.071100   \n",
       "1            59        6.805396   51   0.874016      0.342520  0.400809   \n",
       "2             6       13.671772   44   0.944882      0.724409  0.207723   \n",
       "3            16        4.333286   50   0.889764      0.444882  0.361216   \n",
       "4            20        5.967121   38   0.744094      0.661417  0.068033   \n",
       "...         ...             ...  ...        ...           ...       ...   \n",
       "1995         34       14.013489   41   0.881890      0.744094  0.104838   \n",
       "1996         20        8.380497   38   0.944882      0.877953  0.063851   \n",
       "1997         99        4.626950   36   0.759843      0.744094  0.098703   \n",
       "1998         26        3.281439   46   0.909449      0.598425  0.117803   \n",
       "1999          8        9.405648   48   0.925197      0.539370  0.451973   \n",
       "\n",
       "     product  \n",
       "0          b  \n",
       "1          c  \n",
       "2          b  \n",
       "3          b  \n",
       "4          a  \n",
       "...      ...  \n",
       "1995       b  \n",
       "1996       a  \n",
       "1997       f  \n",
       "1998       c  \n",
       "1999       c  \n",
       "\n",
       "[2000 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?']\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "We generate dummies, fill in the missing values, and standardize our data ranges with a Z-score.\n",
    "\n",
    "This last point is non-trivial and should be elaborated on: if the range of one input neuron is 0 to 1, but another -1 million to 1 million, the NN may take longer to balance the weights, thus require more training and be more error-prone, than a network where all input neurons are in a standardized range.\n",
    "\n",
    "The consequence of using something such as a Z-score, is that the extensiblitly of the NN is limited. Consider a test point that you wish to predict with the NN without knowing the mean or standard deviation of the training set; your prediction will be skewed, since the value cannot be properly normalized.\n",
    "\n",
    "There is much to consider when preparing the data for the NN, and a choice of how to normalize data should be made that is sensitive to how the model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dummies\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df,\n",
    "        pd.get_dummies(df['job'], prefix='job'),\n",
    "        pd.get_dummies(df['area'], prefix='area')\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# fill missing values\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# standardize\n",
    "for col_name in ['income', 'aspect', 'save_rate', 'age', 'subscriptions']:\n",
    "    df[col_name] = zscore(df[col_name])\n",
    "\n",
    "# assemble data vectors\n",
    "x_cols = df.columns.drop('product').drop('id')\n",
    "x = df[x_cols].values\n",
    "\n",
    "dummies = pd.get_dummies(df['product'])\n",
    "products = dummies.columns # index names for dummies\n",
    "y = dummies.values\n",
    "\n",
    "# split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.25,\n",
    "    random_state=414141\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the NN model\n",
    "We construct a dense NN with 3 hidden layers, and an output layer that matches our `y`-vector dimension, with softmax activation, so that the output is normalized and correctly weighted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 182       \n",
      "=================================================================\n",
      "Total params: 11,307\n",
      "Trainable params: 11,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense( # hidden 1\n",
    "        100,\n",
    "        input_dim=x.shape[1],\n",
    "        activation='relu',\n",
    "    ),\n",
    "    tf.keras.layers.Dense( # hidden 2 \n",
    "        50,\n",
    "        activation='relu',\n",
    "    ),\n",
    "    tf.keras.layers.Dense( # hidden 3\n",
    "        25,\n",
    "        activation='relu',\n",
    "    ),\n",
    "    tf.keras.layers.Dense( # output\n",
    "        y.shape[1],\n",
    "        activation='softmax',\n",
    "    )\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'] # more on this below\n",
    ")\n",
    "\n",
    "monitor = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-3,\n",
    "    patience=5,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "We use the early stopping callback we defined during the build step, and train the model over a maxmimum of 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a557e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[monitor],\n",
    "    verbose=0,\n",
    "    epochs=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "We will examine the *accuracy* of the NN, which we define as the number of rows where the NN correctly predicted the target class: we use *accuracy* for classification problems:\n",
    "$$\n",
    "a = \\frac{c}{N}\n",
    "$$\n",
    "with $c$ denoting the number of correct evaluations, with $N$ total number of evaluations. Our model already consider accuracy as the evaluation metric. \n",
    "\n",
    "We can extract the model's prediction with `argmax()` since we used softmax activation in the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred_ind = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a SciKit method for calculating the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.712\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_compare = np.argmax(y_test, axis=1)\n",
    "score = metrics.accuracy_score(y_compare, pred_ind)\n",
    "\n",
    "print(f\"Accuracy score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss\n",
    "We can further evaluate our model by examining the probability predictions of each class. [Log loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) is a metric that penalizes high probabilites in false answers -- lower log loss values are desired. \n",
    "\n",
    "Log loss is calculated with\n",
    "$$\n",
    "L_\\text{log} = \\frac{-1}{N} \\sum_{i=1}^N \\left( y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1-\\hat{y}_i) \\right)\n",
    "$$\n",
    "with $y_i$ the target outcome of row $i$, $\\hat{y}_i$ is the model prediction. This metric is best used for classifications with more than two outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score: 0.650408753653057\n"
     ]
    }
   ],
   "source": [
    "score = metrics.log_loss(y_test, pred)\n",
    "print(f\"Log loss score: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
