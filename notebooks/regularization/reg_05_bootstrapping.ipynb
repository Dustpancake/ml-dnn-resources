{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping Idiom\n",
    "There are multiple hyperparameters introduced by different regularization techniques, which may be adjusted. These include\n",
    "- the number of layers in the NN\n",
    "- how many neurons in a given layer\n",
    "- which activation function to use on each layer\n",
    "- dropout, and if so, what ratio\n",
    "- L1/L2, and if so, with what magnitude Lagrangian multiplier\n",
    "\n",
    "A difficulty exists when trying to measure the effect of these hyperparameters; that is, training the exact same NN setup twice, due to their stochastic nature, may already produce vastly different results independent of the hyperparameters. *Bootstrapping* can be an effective means of benchmarking sets of hyperparameters, since it creates an *ensemble*, mitigating some of the random contribution.\n",
    "\n",
    "Some recipes for training neural networks and determing the best set of hyperparameters exists, such as [this blog post by Andrej Karpathy](http://karpathy.github.io/2019/04/25/recipe/).\n",
    "\n",
    "Similar to cross-validation, *bootstrapping* iterates over a number of folds with validation and training sets. Bootstrapping, however, assembles a new train/validation split every cycle, with potential overlap, allowing bootstrapping methods to continue indefinitely. This means there will also often be repeated rows over enough cycles, and potentially even duplicate cycles entirely.\n",
    "\n",
    "We will explore bootstrapping for hyperparameter benchmarking, and train NN for a specified number of *splits*, after which we compare the average score of each hyperparameter set. This approach should be much less prone to random fluctuation than using e.g. cross-validation for benchmarking.\n",
    "\n",
    "Additionally, the number of *epochs* will be tracked, as this may also give an indication of optimal hyperparameters. There exists a caveat with this, namely that the early stop validation set may *seemingly* improve the network's performance. This is partially also due to stopping and evaluating on the same sample (ideally we would use independent samples). However, since we are using a gross average, this should not present too large of a problem.\n",
    "\n",
    "We will define a helper function for numerical time displays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def hms_string(seconds):\n",
    "    return str(\n",
    "        datetime.timedelta(\n",
    "            seconds=seconds\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling the data\n",
    "Since we will be demonstrating the bootstrapping method over a few examples, we want to hold onto the data and perform some general abstractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>crime</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>kd</td>\n",
       "      <td>c</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.207723</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.361216</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>51017.0</td>\n",
       "      <td>38.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>34</td>\n",
       "      <td>14.013489</td>\n",
       "      <td>41</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.104838</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>26576.0</td>\n",
       "      <td>33.358333</td>\n",
       "      <td>2</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>20</td>\n",
       "      <td>8.380497</td>\n",
       "      <td>38</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.063851</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28595.0</td>\n",
       "      <td>39.425000</td>\n",
       "      <td>3</td>\n",
       "      <td>7.168218</td>\n",
       "      <td>99</td>\n",
       "      <td>4.626950</td>\n",
       "      <td>36</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.098703</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>qp</td>\n",
       "      <td>c</td>\n",
       "      <td>67949.0</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>8.936292</td>\n",
       "      <td>26</td>\n",
       "      <td>3.281439</td>\n",
       "      <td>46</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.117803</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>61467.0</td>\n",
       "      <td>16.891667</td>\n",
       "      <td>0</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>8</td>\n",
       "      <td>9.405648</td>\n",
       "      <td>48</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>0.451973</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id job area   income     aspect  subscriptions  dist_healthy  \\\n",
       "0        1  vv    c  50876.0  13.100000              1      9.017895   \n",
       "1        2  kd    c  60369.0  18.625000              2      7.766643   \n",
       "2        3  pe    c  55126.0  34.766667              1      3.632069   \n",
       "3        4  11    c  51690.0  15.808333              1      5.372942   \n",
       "4        5  kl    d  28347.0  40.941667              3      3.822477   \n",
       "...    ...  ..  ...      ...        ...            ...           ...   \n",
       "1995  1996  vv    c  51017.0  38.233333              1      5.454545   \n",
       "1996  1997  kl    d  26576.0  33.358333              2      3.632069   \n",
       "1997  1998  kl    d  28595.0  39.425000              3      7.168218   \n",
       "1998  1999  qp    c  67949.0   5.733333              0      8.936292   \n",
       "1999  2000  pe    c  61467.0  16.891667              0      4.312097   \n",
       "\n",
       "      save_rate  dist_unhealthy  age  pop_dense  retail_dense     crime  \\\n",
       "0            35       11.738935   49   0.885827      0.492126  0.071100   \n",
       "1            59        6.805396   51   0.874016      0.342520  0.400809   \n",
       "2             6       13.671772   44   0.944882      0.724409  0.207723   \n",
       "3            16        4.333286   50   0.889764      0.444882  0.361216   \n",
       "4            20        5.967121   38   0.744094      0.661417  0.068033   \n",
       "...         ...             ...  ...        ...           ...       ...   \n",
       "1995         34       14.013489   41   0.881890      0.744094  0.104838   \n",
       "1996         20        8.380497   38   0.944882      0.877953  0.063851   \n",
       "1997         99        4.626950   36   0.759843      0.744094  0.098703   \n",
       "1998         26        3.281439   46   0.909449      0.598425  0.117803   \n",
       "1999          8        9.405648   48   0.925197      0.539370  0.451973   \n",
       "\n",
       "     product  \n",
       "0          b  \n",
       "1          c  \n",
       "2          b  \n",
       "3          b  \n",
       "4          a  \n",
       "...      ...  \n",
       "1995       b  \n",
       "1996       a  \n",
       "1997       f  \n",
       "1998       c  \n",
       "1999       c  \n",
       "\n",
       "[2000 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dummies and fill missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df,\n",
    "        pd.get_dummies(df['job'], prefix='job'),\n",
    "        pd.get_dummies(df['area'], prefix='area')\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.drop(['job', 'area'], axis=1, inplace=True)\n",
    "\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "for i in ['income', 'aspect', 'save_rate', 'subscriptions']:\n",
    "    df[i] = scipy.stats.zscore(\n",
    "        df[i]\n",
    "    )\n",
    "\n",
    "# save copy\n",
    "_df = df.copy()\n",
    "    \n",
    "def renew_data():\n",
    "    return _df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the environment\n",
    "Since we will be performing much the same task for different models, we will define a few functions that enact the bootstrapping for us, which we can call in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bootstrap_step(x, y, model, train, test, score_, mean_store, epoch_store):\n",
    "    \"\"\" score_ is a callback for scoring, \n",
    "        mean and epoch store are lists\n",
    "        - trains and evaluates the model, \n",
    "        - returns info string \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    monitor = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        min_delta=1e-3, \n",
    "        patience=5, \n",
    "        verbose=0, \n",
    "        mode='min', \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[monitor],\n",
    "        verbose=0,\n",
    "        epochs=1000\n",
    "    )\n",
    "    \n",
    "    # get number of epochs until stopped\n",
    "    epochs = monitor.stopped_epoch\n",
    "    epoch_store.append(epochs)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # calculate score and store\n",
    "    score = score_(pred, y_test)\n",
    "    mean_store.append(score)\n",
    "    \n",
    "    # calculate means and stds\n",
    "    score_mean = np.mean(mean_store)\n",
    "    score_std = np.std(mean_store)\n",
    "    \n",
    "    epoch_mean = np.mean(epoch_store)\n",
    "    \n",
    "    # end timer\n",
    "    duration = time.time() - start_time\n",
    "    return (\n",
    "        f\"score: {score:.3f} | mean: {score_mean:.3f} | std: {score_std:.3f}\\n\"\n",
    "        f\"epochs: {epochs} | mean: {int(epoch_mean)} | time: {hms_string(duration)}\"\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Regression\n",
    "Regression boostraps use the `ShuffleSplit` class, which, analogous to `KFold`, does not balance the train/validation splits. We finish preparing the data for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = renew_data()\n",
    "\n",
    "df = pd.concat(\n",
    "    [ \n",
    "        df,pd.get_dummies(df['product'], prefix=\"product\") \n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "x_cols = df.columns.drop('age').drop('id')\n",
    "x = df[x_cols].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = 50\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "\n",
    "def new_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(\n",
    "            20,\n",
    "            input_dim=x.shape[1],\n",
    "            activation='relu'\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            10,\n",
    "            activation='relu'\n",
    "        ),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_func(pred, y_test):\n",
    "    return np.sqrt(\n",
    "        sklearn.metrics.mean_squared_error(\n",
    "            pred, y_test\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using bootstrapping, we invoke our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- trial 1 ---------------------\n",
      "score: 0.561 | mean: 0.561 | std: 0.000\n",
      "epochs: 120 | mean: 120 | time: 0:00:15.275265\n",
      "--- trial 2 ---------------------\n",
      "score: 0.597 | mean: 0.579 | std: 0.018\n",
      "epochs: 116 | mean: 118 | time: 0:00:07.917888\n",
      "--- trial 3 ---------------------\n",
      "score: 1.033 | mean: 0.730 | std: 0.215\n",
      "epochs: 94 | mean: 110 | time: 0:00:06.481990\n",
      "--- trial 4 ---------------------\n",
      "score: 0.993 | mean: 0.796 | std: 0.218\n",
      "epochs: 95 | mean: 106 | time: 0:00:06.642428\n",
      "--- trial 5 ---------------------\n",
      "score: 1.151 | mean: 0.867 | std: 0.241\n",
      "epochs: 104 | mean: 105 | time: 0:00:07.310214\n",
      "--- trial 6 ---------------------\n",
      "score: 0.508 | mean: 0.807 | std: 0.258\n",
      "epochs: 113 | mean: 107 | time: 0:00:07.695861\n",
      "--- trial 7 ---------------------\n",
      "score: 0.683 | mean: 0.790 | std: 0.242\n",
      "epochs: 151 | mean: 113 | time: 0:00:10.125791\n",
      "--- trial 8 ---------------------\n",
      "score: 0.797 | mean: 0.791 | std: 0.227\n",
      "epochs: 100 | mean: 111 | time: 0:00:07.049929\n",
      "--- trial 9 ---------------------\n",
      "score: 0.617 | mean: 0.771 | std: 0.221\n",
      "epochs: 184 | mean: 119 | time: 0:00:12.516948\n",
      "--- trial 10 ---------------------\n",
      "score: 0.885 | mean: 0.783 | std: 0.212\n",
      "epochs: 109 | mean: 118 | time: 0:00:07.364269\n",
      "--- trial 11 ---------------------\n",
      "score: 0.718 | mean: 0.777 | std: 0.203\n",
      "epochs: 113 | mean: 118 | time: 0:00:07.469710\n",
      "--- trial 12 ---------------------\n",
      "score: 0.719 | mean: 0.772 | std: 0.195\n",
      "epochs: 110 | mean: 117 | time: 0:00:07.797601\n",
      "--- trial 13 ---------------------\n",
      "score: 0.854 | mean: 0.778 | std: 0.189\n",
      "epochs: 106 | mean: 116 | time: 0:00:07.285966\n",
      "--- trial 14 ---------------------\n",
      "score: 0.509 | mean: 0.759 | std: 0.195\n",
      "epochs: 131 | mean: 117 | time: 0:00:08.913973\n",
      "--- trial 15 ---------------------\n",
      "score: 0.471 | mean: 0.740 | std: 0.201\n",
      "epochs: 140 | mean: 119 | time: 0:00:09.705238\n",
      "--- trial 16 ---------------------\n",
      "score: 0.643 | mean: 0.734 | std: 0.196\n",
      "epochs: 102 | mean: 118 | time: 0:00:07.226749\n",
      "--- trial 17 ---------------------\n",
      "score: 0.720 | mean: 0.733 | std: 0.190\n",
      "epochs: 126 | mean: 118 | time: 0:00:08.595742\n",
      "--- trial 18 ---------------------\n",
      "score: 0.701 | mean: 0.731 | std: 0.185\n",
      "epochs: 91 | mean: 116 | time: 0:00:06.195138\n",
      "--- trial 19 ---------------------\n",
      "score: 0.867 | mean: 0.738 | std: 0.183\n",
      "epochs: 108 | mean: 116 | time: 0:00:07.386958\n",
      "--- trial 20 ---------------------\n",
      "score: 0.756 | mean: 0.739 | std: 0.178\n",
      "epochs: 138 | mean: 117 | time: 0:00:09.472500\n",
      "--- trial 21 ---------------------\n",
      "score: 0.797 | mean: 0.742 | std: 0.174\n",
      "epochs: 132 | mean: 118 | time: 0:00:09.103126\n",
      "--- trial 22 ---------------------\n",
      "score: 0.835 | mean: 0.746 | std: 0.171\n",
      "epochs: 102 | mean: 117 | time: 0:00:06.897603\n",
      "--- trial 23 ---------------------\n",
      "score: 0.772 | mean: 0.747 | std: 0.168\n",
      "epochs: 139 | mean: 118 | time: 0:00:09.676271\n",
      "--- trial 24 ---------------------\n",
      "score: 0.677 | mean: 0.744 | std: 0.165\n",
      "epochs: 153 | mean: 119 | time: 0:00:10.363383\n",
      "--- trial 25 ---------------------\n",
      "score: 0.785 | mean: 0.746 | std: 0.162\n",
      "epochs: 136 | mean: 120 | time: 0:00:09.208393\n",
      "--- trial 26 ---------------------\n",
      "score: 0.774 | mean: 0.747 | std: 0.159\n",
      "epochs: 137 | mean: 121 | time: 0:00:09.455889\n",
      "--- trial 27 ---------------------\n",
      "score: 0.579 | mean: 0.741 | std: 0.159\n",
      "epochs: 113 | mean: 120 | time: 0:00:07.954813\n",
      "--- trial 28 ---------------------\n",
      "score: 1.435 | mean: 0.766 | std: 0.202\n",
      "epochs: 104 | mean: 120 | time: 0:00:07.225795\n",
      "--- trial 29 ---------------------\n",
      "score: 0.653 | mean: 0.762 | std: 0.200\n",
      "epochs: 125 | mean: 120 | time: 0:00:08.535306\n",
      "--- trial 30 ---------------------\n",
      "score: 0.671 | mean: 0.759 | std: 0.197\n",
      "epochs: 123 | mean: 120 | time: 0:00:08.874860\n",
      "--- trial 31 ---------------------\n",
      "score: 0.741 | mean: 0.758 | std: 0.194\n",
      "epochs: 94 | mean: 119 | time: 0:00:06.605844\n",
      "--- trial 32 ---------------------\n",
      "score: 0.828 | mean: 0.760 | std: 0.191\n",
      "epochs: 173 | mean: 121 | time: 0:00:11.716974\n",
      "--- trial 33 ---------------------\n",
      "score: 0.950 | mean: 0.766 | std: 0.191\n",
      "epochs: 95 | mean: 120 | time: 0:00:06.747673\n",
      "--- trial 34 ---------------------\n",
      "score: 0.575 | mean: 0.761 | std: 0.191\n",
      "epochs: 130 | mean: 120 | time: 0:00:08.924448\n",
      "--- trial 35 ---------------------\n",
      "score: 0.715 | mean: 0.759 | std: 0.188\n",
      "epochs: 120 | mean: 120 | time: 0:00:08.333730\n",
      "--- trial 36 ---------------------\n",
      "score: 0.596 | mean: 0.755 | std: 0.188\n",
      "epochs: 128 | mean: 120 | time: 0:00:08.710403\n",
      "--- trial 37 ---------------------\n",
      "score: 0.663 | mean: 0.752 | std: 0.186\n",
      "epochs: 103 | mean: 120 | time: 0:00:07.170061\n",
      "--- trial 38 ---------------------\n",
      "score: 0.711 | mean: 0.751 | std: 0.183\n",
      "epochs: 152 | mean: 121 | time: 0:00:10.343078\n",
      "--- trial 39 ---------------------\n",
      "score: 0.526 | mean: 0.745 | std: 0.185\n",
      "epochs: 140 | mean: 121 | time: 0:00:09.535291\n",
      "--- trial 40 ---------------------\n",
      "score: 0.558 | mean: 0.741 | std: 0.185\n",
      "epochs: 109 | mean: 121 | time: 0:00:07.626791\n",
      "--- trial 41 ---------------------\n",
      "score: 0.583 | mean: 0.737 | std: 0.184\n",
      "epochs: 133 | mean: 121 | time: 0:00:09.118294\n",
      "--- trial 42 ---------------------\n",
      "score: 0.951 | mean: 0.742 | std: 0.185\n",
      "epochs: 125 | mean: 121 | time: 0:00:08.553513\n",
      "--- trial 43 ---------------------\n",
      "score: 0.659 | mean: 0.740 | std: 0.183\n",
      "epochs: 114 | mean: 121 | time: 0:00:07.684201\n",
      "--- trial 44 ---------------------\n",
      "score: 0.724 | mean: 0.740 | std: 0.181\n",
      "epochs: 114 | mean: 121 | time: 0:00:07.919048\n",
      "--- trial 45 ---------------------\n",
      "score: 0.558 | mean: 0.736 | std: 0.181\n",
      "epochs: 113 | mean: 121 | time: 0:00:07.918115\n",
      "--- trial 46 ---------------------\n",
      "score: 0.616 | mean: 0.733 | std: 0.180\n",
      "epochs: 129 | mean: 121 | time: 0:00:08.740370\n",
      "--- trial 47 ---------------------\n",
      "score: 0.834 | mean: 0.735 | std: 0.178\n",
      "epochs: 145 | mean: 121 | time: 0:00:09.958981\n",
      "--- trial 48 ---------------------\n",
      "score: 0.829 | mean: 0.737 | std: 0.177\n",
      "epochs: 88 | mean: 121 | time: 0:00:06.186146\n",
      "--- trial 49 ---------------------\n",
      "score: 0.563 | mean: 0.734 | std: 0.177\n",
      "epochs: 126 | mean: 121 | time: 0:00:08.773112\n",
      "--- trial 50 ---------------------\n",
      "score: 0.717 | mean: 0.733 | std: 0.175\n",
      "epochs: 111 | mean: 121 | time: 0:00:07.837173\n"
     ]
    }
   ],
   "source": [
    "boot = sklearn.model_selection.ShuffleSplit(\n",
    "    n_splits=SPLITS,\n",
    "    test_size=0.1,\n",
    "    random_state=414141\n",
    ")\n",
    "\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "\n",
    "counter = 0\n",
    "for train, test in boot.split(x):\n",
    "    counter += 1\n",
    "    \n",
    "    model = new_model()\n",
    "    \n",
    "    info = bootstrap_step(\n",
    "        x, y,\n",
    "        model,\n",
    "        train, test,\n",
    "        score_func,\n",
    "        mean_benchmark,\n",
    "        epochs_needed\n",
    "    )\n",
    "    \n",
    "    print(f\"--- trial {counter} ---------------------\")\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Classification\n",
    "The approach to classification bootstrapping is very similar as with regression. Only now, we instead use `StratifiedShuffleSplit`, for the same reasons as with $k$-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = renew_data()\n",
    "\n",
    "df['age'] = scipy.stats.zscore(df['age'])\n",
    "\n",
    "x_cols = df.columns.drop('product').drop('id')\n",
    "x = df[x_cols].values\n",
    "\n",
    "dummies = pd.get_dummies(df['product'])\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we define our model construction and testing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = 50\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "\n",
    "def new_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(\n",
    "            50,\n",
    "            input_dim=x.shape[1],\n",
    "            activation='relu'\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            25,\n",
    "            activation='relu'\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            y.shape[1],\n",
    "            activation='softmax'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_func(pred, y_test):\n",
    "    y_compare = np.argmax(y_test,axis=1)\n",
    "    return sklearn.metrics.log_loss(\n",
    "        y_compare, pred\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run just as before, with the exception of using a different bootstrapper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- trial 1 ---------------------\n",
      "score: 0.697 | mean: 0.697 | std: 0.000\n",
      "epochs: 40 | mean: 40 | time: 0:00:03.414883\n",
      "--- trial 2 ---------------------\n",
      "score: 0.653 | mean: 0.675 | std: 0.022\n",
      "epochs: 28 | mean: 34 | time: 0:00:02.359109\n",
      "--- trial 3 ---------------------\n",
      "score: 0.685 | mean: 0.678 | std: 0.019\n",
      "epochs: 30 | mean: 32 | time: 0:00:02.658177\n",
      "--- trial 4 ---------------------\n",
      "score: 0.618 | mean: 0.663 | std: 0.031\n",
      "epochs: 41 | mean: 34 | time: 0:00:03.514177\n",
      "--- trial 5 ---------------------\n",
      "score: 0.619 | mean: 0.654 | std: 0.033\n",
      "epochs: 39 | mean: 35 | time: 0:00:03.241857\n",
      "--- trial 6 ---------------------\n",
      "score: 0.705 | mean: 0.663 | std: 0.035\n",
      "epochs: 17 | mean: 32 | time: 0:00:01.670558\n",
      "--- trial 7 ---------------------\n",
      "score: 0.713 | mean: 0.670 | std: 0.037\n",
      "epochs: 27 | mean: 31 | time: 0:00:02.581623\n",
      "--- trial 8 ---------------------\n",
      "score: 0.740 | mean: 0.679 | std: 0.042\n",
      "epochs: 14 | mean: 29 | time: 0:00:01.436481\n",
      "--- trial 9 ---------------------\n",
      "score: 0.577 | mean: 0.668 | std: 0.051\n",
      "epochs: 25 | mean: 29 | time: 0:00:02.278402\n",
      "--- trial 10 ---------------------\n",
      "score: 0.769 | mean: 0.678 | std: 0.057\n",
      "epochs: 21 | mean: 28 | time: 0:00:01.986902\n",
      "--- trial 11 ---------------------\n",
      "score: 0.656 | mean: 0.676 | std: 0.055\n",
      "epochs: 23 | mean: 27 | time: 0:00:01.903722\n",
      "--- trial 12 ---------------------\n",
      "score: 0.659 | mean: 0.674 | std: 0.052\n",
      "epochs: 19 | mean: 27 | time: 0:00:01.819110\n",
      "--- trial 13 ---------------------\n",
      "score: 0.685 | mean: 0.675 | std: 0.050\n",
      "epochs: 19 | mean: 26 | time: 0:00:01.762432\n",
      "--- trial 14 ---------------------\n",
      "score: 0.691 | mean: 0.676 | std: 0.049\n",
      "epochs: 28 | mean: 26 | time: 0:00:02.487001\n",
      "--- trial 15 ---------------------\n",
      "score: 0.638 | mean: 0.674 | std: 0.048\n",
      "epochs: 29 | mean: 26 | time: 0:00:02.398561\n",
      "--- trial 16 ---------------------\n",
      "score: 0.659 | mean: 0.673 | std: 0.047\n",
      "epochs: 32 | mean: 27 | time: 0:00:02.986086\n",
      "--- trial 17 ---------------------\n",
      "score: 0.647 | mean: 0.671 | std: 0.046\n",
      "epochs: 28 | mean: 27 | time: 0:00:02.460297\n",
      "--- trial 18 ---------------------\n",
      "score: 0.644 | mean: 0.670 | std: 0.045\n",
      "epochs: 34 | mean: 27 | time: 0:00:02.915484\n",
      "--- trial 19 ---------------------\n",
      "score: 0.698 | mean: 0.671 | std: 0.044\n",
      "epochs: 26 | mean: 27 | time: 0:00:02.346349\n",
      "--- trial 20 ---------------------\n",
      "score: 0.680 | mean: 0.672 | std: 0.043\n",
      "epochs: 30 | mean: 27 | time: 0:00:02.648295\n",
      "--- trial 21 ---------------------\n",
      "score: 0.715 | mean: 0.674 | std: 0.043\n",
      "epochs: 26 | mean: 27 | time: 0:00:02.289677\n",
      "--- trial 22 ---------------------\n",
      "score: 0.685 | mean: 0.674 | std: 0.042\n",
      "epochs: 36 | mean: 27 | time: 0:00:03.109770\n",
      "--- trial 23 ---------------------\n",
      "score: 0.682 | mean: 0.675 | std: 0.041\n",
      "epochs: 27 | mean: 27 | time: 0:00:02.384693\n",
      "--- trial 24 ---------------------\n",
      "score: 0.743 | mean: 0.678 | std: 0.043\n",
      "epochs: 22 | mean: 27 | time: 0:00:02.029285\n",
      "--- trial 25 ---------------------\n",
      "score: 0.690 | mean: 0.678 | std: 0.042\n",
      "epochs: 17 | mean: 27 | time: 0:00:01.658942\n",
      "--- trial 26 ---------------------\n",
      "score: 0.736 | mean: 0.680 | std: 0.043\n",
      "epochs: 23 | mean: 26 | time: 0:00:02.322873\n",
      "--- trial 27 ---------------------\n",
      "score: 0.658 | mean: 0.679 | std: 0.042\n",
      "epochs: 24 | mean: 26 | time: 0:00:02.104839\n",
      "--- trial 28 ---------------------\n",
      "score: 0.735 | mean: 0.681 | std: 0.042\n",
      "epochs: 27 | mean: 26 | time: 0:00:02.208648\n",
      "--- trial 29 ---------------------\n",
      "score: 0.704 | mean: 0.682 | std: 0.042\n",
      "epochs: 23 | mean: 26 | time: 0:00:02.118737\n",
      "--- trial 30 ---------------------\n",
      "score: 0.712 | mean: 0.683 | std: 0.042\n",
      "epochs: 17 | mean: 26 | time: 0:00:01.674844\n",
      "--- trial 31 ---------------------\n",
      "score: 0.691 | mean: 0.683 | std: 0.041\n",
      "epochs: 22 | mean: 26 | time: 0:00:02.035546\n",
      "--- trial 32 ---------------------\n",
      "score: 0.618 | mean: 0.681 | std: 0.042\n",
      "epochs: 27 | mean: 26 | time: 0:00:02.441857\n",
      "--- trial 33 ---------------------\n",
      "score: 0.672 | mean: 0.681 | std: 0.041\n",
      "epochs: 21 | mean: 26 | time: 0:00:01.957485\n",
      "--- trial 34 ---------------------\n",
      "score: 0.707 | mean: 0.682 | std: 0.041\n",
      "epochs: 22 | mean: 26 | time: 0:00:02.017754\n",
      "--- trial 35 ---------------------\n",
      "score: 0.766 | mean: 0.684 | std: 0.043\n",
      "epochs: 15 | mean: 25 | time: 0:00:01.697168\n",
      "--- trial 36 ---------------------\n",
      "score: 0.733 | mean: 0.686 | std: 0.043\n",
      "epochs: 32 | mean: 25 | time: 0:00:02.839708\n",
      "--- trial 37 ---------------------\n",
      "score: 0.561 | mean: 0.682 | std: 0.047\n",
      "epochs: 34 | mean: 26 | time: 0:00:02.914866\n",
      "--- trial 38 ---------------------\n",
      "score: 0.698 | mean: 0.683 | std: 0.046\n",
      "epochs: 39 | mean: 26 | time: 0:00:03.268480\n",
      "--- trial 39 ---------------------\n",
      "score: 0.660 | mean: 0.682 | std: 0.046\n",
      "epochs: 21 | mean: 26 | time: 0:00:01.918860\n",
      "--- trial 40 ---------------------\n",
      "score: 0.654 | mean: 0.681 | std: 0.045\n",
      "epochs: 20 | mean: 26 | time: 0:00:01.928016\n",
      "--- trial 41 ---------------------\n",
      "score: 0.673 | mean: 0.681 | std: 0.045\n",
      "epochs: 27 | mean: 26 | time: 0:00:02.370411\n",
      "--- trial 42 ---------------------\n",
      "score: 0.746 | mean: 0.683 | std: 0.045\n",
      "epochs: 19 | mean: 25 | time: 0:00:01.827067\n",
      "--- trial 43 ---------------------\n",
      "score: 0.678 | mean: 0.683 | std: 0.045\n",
      "epochs: 20 | mean: 25 | time: 0:00:01.894390\n",
      "--- trial 44 ---------------------\n",
      "score: 0.645 | mean: 0.682 | std: 0.045\n",
      "epochs: 24 | mean: 25 | time: 0:00:02.209211\n",
      "--- trial 45 ---------------------\n",
      "score: 0.639 | mean: 0.681 | std: 0.045\n",
      "epochs: 48 | mean: 26 | time: 0:00:03.799485\n",
      "--- trial 46 ---------------------\n",
      "score: 0.693 | mean: 0.681 | std: 0.044\n",
      "epochs: 31 | mean: 26 | time: 0:00:02.949763\n",
      "--- trial 47 ---------------------\n",
      "score: 0.781 | mean: 0.683 | std: 0.046\n",
      "epochs: 19 | mean: 26 | time: 0:00:01.820151\n",
      "--- trial 48 ---------------------\n",
      "score: 0.675 | mean: 0.683 | std: 0.046\n",
      "epochs: 41 | mean: 26 | time: 0:00:03.502294\n",
      "--- trial 49 ---------------------\n",
      "score: 0.764 | mean: 0.685 | std: 0.047\n",
      "epochs: 25 | mean: 26 | time: 0:00:02.279292\n",
      "--- trial 50 ---------------------\n",
      "score: 0.655 | mean: 0.684 | std: 0.046\n",
      "epochs: 32 | mean: 26 | time: 0:00:02.588075\n"
     ]
    }
   ],
   "source": [
    "boot = sklearn.model_selection.StratifiedShuffleSplit(\n",
    "    n_splits=SPLITS,\n",
    "    test_size=0.1,\n",
    "    random_state=414141\n",
    ")\n",
    "\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "\n",
    "counter = 0\n",
    "for train, test in boot.split(x, df['product']):\n",
    "    counter += 1\n",
    "    \n",
    "    model = new_model()\n",
    "    \n",
    "    info = bootstrap_step(\n",
    "        x, y,\n",
    "        model,\n",
    "        train, test,\n",
    "        score_func,\n",
    "        mean_benchmark,\n",
    "        epochs_needed\n",
    "    )\n",
    "    \n",
    "    print(f\"--- trial {counter} ---------------------\")\n",
    "    print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
